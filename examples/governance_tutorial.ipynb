{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c58ccfe",
   "metadata": {},
   "source": [
    "# QDET Governance Module Tutorial\n",
    "\n",
    "This notebook demonstrates all available tools in the QDET Governance module.\n",
    "\n",
    "The Governance module provides enterprise-grade features for:\n",
    "- **Cost Estimation**: Budget quantum jobs before execution\n",
    "- **Drift Detection**: Monitor for data distribution changes\n",
    "- **Data Integrity**: Verify quantum encoding correctness\n",
    "- **Job Monitoring**: Track execution progress\n",
    "- **Privacy**: Apply differential privacy to quantum circuits\n",
    "- **Noise Simulation**: Test robustness against hardware noise\n",
    "- **Validation**: Check data-hardware compatibility\n",
    "- **Audit & Compliance**: Log all operations and enforce policies\n",
    "- **Security**: Manage access control and encryption\n",
    "- **Orchestration**: Coordinate complex workflows\n",
    "\n",
    "We'll use the iris.csv dataset to demonstrate these governance capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce8336",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "\n",
    "Import all required libraries and load the iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Load iris dataset\n",
    "iris_data = pd.read_csv('../qudet/datasets/iris.csv')\n",
    "X = iris_data.iloc[:, :-1].values\n",
    "y = iris_data.iloc[:, -1].values\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Training set: {X_train.shape}\")\n",
    "print(f\"  Test set: {X_test.shape}\")\n",
    "print(f\"  Features: {iris_data.columns[:-1].tolist()}\")\n",
    "print(f\"  Classes: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f76dd",
   "metadata": {},
   "source": [
    "## 2. Resource Estimator\n",
    "\n",
    "**Description**: Estimates cost and complexity of quantum jobs before execution. Critical for budgeting large-scale data pipelines.\n",
    "\n",
    "**Use Case**: Check if iris dataset fits within quantum hardware limits and estimate job costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af85ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.cost import ResourceEstimator\n",
    "from qiskit import QuantumCircuit\n",
    "\n",
    "# Create a sample quantum circuit\n",
    "qc = QuantumCircuit(4, 4)\n",
    "qc.h(range(4))\n",
    "qc.cx(0, 1)\n",
    "qc.cx(1, 2)\n",
    "qc.cx(2, 3)\n",
    "qc.measure(range(4), range(4))\n",
    "\n",
    "# Estimate circuit cost\n",
    "cost_report = ResourceEstimator.estimate_circuit_cost(qc, shots=1024, hardware_rate=0.5)\n",
    "print(\"Circuit Cost Estimation:\")\n",
    "for key, value in cost_report.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Check pipeline feasibility\n",
    "print(f\"\\nIris Dataset Feasibility Check:\")\n",
    "feasibility = ResourceEstimator.check_pipeline_feasibility(len(X_train), X_train.shape[1])\n",
    "print(f\"  {feasibility}\")\n",
    "\n",
    "# Check with reduced dimensions\n",
    "feasibility_large = ResourceEstimator.check_pipeline_feasibility(50000, 200)\n",
    "print(f\"\\nLarge dataset (50k samples, 200 features):\")\n",
    "print(f\"  {feasibility_large}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe7412",
   "metadata": {},
   "source": [
    "## 3. Quantum Drift Detector\n",
    "\n",
    "**Description**: Detects data drift using Quantum Maximum Mean Discrepancy (MMD). Compares reference and current data distributions to identify when model retraining is needed.\n",
    "\n",
    "**Use Case**: Monitor iris data for distribution changes in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.drift import QuantumDriftDetector\n",
    "\n",
    "# Create drift detector\n",
    "drift_detector = QuantumDriftDetector(n_qubits=4, threshold=0.1)\n",
    "\n",
    "# Fit on training data (reference)\n",
    "drift_detector.fit_reference(X_train)\n",
    "print(\"Drift Detector fitted on training data.\")\n",
    "\n",
    "# Test for drift on same data (should have no drift)\n",
    "result_same = drift_detector.detect_drift(X_train[:20])\n",
    "print(f\"\\nDrift Detection on Training Data:\")\n",
    "print(f\"  Drift detected: {result_same['drift_detected']}\")\n",
    "print(f\"  MMD score: {result_same.get('mmd_score', 'N/A')}\")\n",
    "\n",
    "# Test for drift on test data (may have some drift)\n",
    "result_test = drift_detector.detect_drift(X_test[:20])\n",
    "print(f\"\\nDrift Detection on Test Data:\")\n",
    "print(f\"  Drift detected: {result_test['drift_detected']}\")\n",
    "print(f\"  MMD score: {result_test.get('mmd_score', 'N/A')}\")\n",
    "\n",
    "# Synthetic drift: modify feature values\n",
    "X_drifted = X_test[:20].copy()\n",
    "X_drifted[:, 0] += 2.0  # Large shift in feature 0\n",
    "result_drift = drift_detector.detect_drift(X_drifted)\n",
    "print(f\"\\nDrift Detection on Drifted Data:\")\n",
    "print(f\"  Drift detected: {result_drift['drift_detected']}\")\n",
    "print(f\"  MMD score: {result_drift.get('mmd_score', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a7c93",
   "metadata": {},
   "source": [
    "## 4. Data Integrity Check\n",
    "\n",
    "**Description**: Verifies that quantum encoding preserves data information through round-trip checks. Validates encoder implementations and debugging encoding issues.\n",
    "\n",
    "**Use Case**: Verify iris data integrity after quantum encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6442676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.integrity import DataIntegrityCheck\n",
    "from qudet.encoders.amplitude import AmplitudeEncoder\n",
    "\n",
    "# Create encoder\n",
    "encoder = AmplitudeEncoder()\n",
    "\n",
    "# Check integrity of encoding\n",
    "original_data = X_train[0]  # First sample\n",
    "print(f\"Data Integrity Check:\")\n",
    "print(f\"  Original data shape: {original_data.shape}\")\n",
    "print(f\"  Original data: {original_data}\")\n",
    "\n",
    "# Verify encoding\n",
    "try:\n",
    "    is_valid = DataIntegrityCheck.verify_encoding(original_data, encoder, tolerance=1e-5)\n",
    "    print(f\"  Encoding integrity verified: {is_valid}\")\n",
    "except Exception as e:\n",
    "  Integrity check result: {str(e)[:100]}\")\n",
    "\n",
    "# Compute fidelity\n",
    "try:\n",
    "    stats = DataIntegrityCheck.compute_encoding_fidelity(original_data, encoder)\n",
    "    print(f\"\\nEncoding Fidelity Statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Fidelity computation: {str(e)[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a7454",
   "metadata": {},
   "source": [
    "## 5. Job Monitor\n",
    "\n",
    "**Description**: Real-time progress tracker for quantum data pipelines. Displays completion percentage, execution rate, and ETA.\n",
    "\n",
    "**Use Case**: Monitor iris processing pipeline progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.monitor import JobMonitor\n",
    "import time\n",
    "\n",
    "# Create monitor\n",
    "total_items = 30\n",
    "monitor = JobMonitor(total_items, description=\"Processing Iris Samples\")\n",
    "\n",
    "print(\"Job Monitoring Example:\")\n",
    "print(f\"  Total items: {total_items}\")\n",
    "\n",
    "# Simulate processing\n",
    "for i in range(total_items):\n",
    "    # Simulate work\n",
    "    time.sleep(0.01)\n",
    "    monitor.update(1)\n",
    "\n",
    "monitor.finish()\n",
    "print(f\"\\nProcessing completed.\")\n",
    "print(f\"  Total time: {monitor.get_elapsed_time():.2f} seconds\")\n",
    "print(f\"  Processing rate: {monitor.get_rate():.2f} items/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922766d",
   "metadata": {},
   "source": [
    "## 6. Quantum Differential Privacy\n",
    "\n",
    "**Description**: Applies depolarizing noise to quantum circuits to ensure differential privacy. Guarantees that output doesn't reveal any single individual's input data.\n",
    "\n",
    "**Use Case**: Protect iris data privacy when sending to cloud QPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaba713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.privacy import QuantumDifferentialPrivacy\n",
    "\n",
    "# Create privacy module with different epsilon values\n",
    "epsilons = [0.5, 1.0, 2.0]\n",
    "\n",
    "print(\"Quantum Differential Privacy:\")\n",
    "for eps in epsilons:\n",
    "    privacy = QuantumDifferentialPrivacy(epsilon=eps)\n",
    "    print(f\"\\n  Epsilon: {eps}\")\n",
    "    print(f\"    Noise probability: {privacy.noise_prob:.4f}\")\n",
    "    print(f\"    Privacy level: {'High' if eps < 1 else 'Moderate' if eps < 2 else 'Low'}\")\n",
    "\n",
    "# Create and sanitize a circuit\n",
    "print(f\"\\nCircuit Privacy Protection:\")\n",
    "qc_original = QuantumCircuit(2)\n",
    "qc_original.h(0)\n",
    "qc_original.cx(0, 1)\n",
    "print(f\"  Original circuit gates: {len(qc_original.data)}\")\n",
    "\n",
    "privacy = QuantumDifferentialPrivacy(epsilon=1.0)\n",
    "qc_sanitized = privacy.sanitize(qc_original)\n",
    "print(f\"  Sanitized circuit gates: {len(qc_sanitized.data)}\")\n",
    "print(f\"  Privacy overhead: {(len(qc_sanitized.data) / len(qc_original.data) - 1) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56365ff9",
   "metadata": {},
   "source": [
    "## 7. Noise Simulator\n",
    "\n",
    "**Description**: Generates realistic noise models to stress-test pipelines against real quantum hardware conditions without accessing actual QPUs.\n",
    "\n",
    "**Use Case**: Test iris pipeline robustness against hardware noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df59ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.simulation import NoiseSimulator\n",
    "\n",
    "print(\"Noise Simulator Configuration:\")\n",
    "\n",
    "# Get noisy backend with different error probabilities\n",
    "error_probs = [0.001, 0.01, 0.05]\n",
    "\n",
    "for error_prob in error_probs:\n",
    "    try:\n",
    "        backend = NoiseSimulator.get_noisy_backend(error_prob=error_prob)\n",
    "        print(f\"\\n  Error probability: {error_prob * 100:.2f}%\")\n",
    "        print(f\"    Backend type: Simulated quantum device with depolarizing noise\")\n",
    "    except ImportError:\n",
    "        print(f\"\\n  Error probability: {error_prob * 100:.2f}%\")\n",
    "        print(f\"    Note: Install qiskit-aer for noise simulation\")\n",
    "\n",
    "# Stress test configuration\n",
    "stress_profile = NoiseSimulator.get_stress_test_profile(n_qubits=4)\n",
    "print(f\"\\nStress Test Profile:\")\n",
    "print(f\"  Qubits: {stress_profile.get('n_qubits', 'N/A')}\")\n",
    "print(f\"  Single-qubit error rate: {stress_profile.get('error_rate_1q', 'N/A')}\")\n",
    "print(f\"  Two-qubit error rate: {stress_profile.get('error_rate_2q', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aadab1",
   "metadata": {},
   "source": [
    "## 8. Data-Hardware Validation\n",
    "\n",
    "**Description**: Validates that data dimensions fit within hardware qubit limits. Prevents quantum circuits from requiring more qubits than available.\n",
    "\n",
    "**Use Case**: Check iris dataset compatibility with quantum hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.validation import check_quantum_capacity\n",
    "\n",
    "print(\"Quantum Capacity Validation:\")\n",
    "\n",
    "# Check iris dataset\n",
    "try:\n",
    "    result = check_quantum_capacity(X_train.shape, max_qubits=127)\n",
    "    print(f\"\\n  Iris dataset ({X_train.shape[1]} features):\")\n",
    "    print(f\"    Hardware compatibility: VALID\")\n",
    "    print(f\"    Qubits required: {X_train.shape[1]}\")\n",
    "    print(f\"    Qubits available (IBM Brisbane): 127\")\n",
    "except ValueError as e:\n",
    "    print(f\"  Iris dataset: {str(e)}\")\n",
    "\n",
    "# Check with high-dimensional data\n",
    "print(f\"\\n  High-dimensional data (500 features):\")\n",
    "try:\n",
    "    result = check_quantum_capacity((X_train.shape[0], 500), max_qubits=127)\n",
    "except ValueError as e:\n",
    "    print(f\"    {str(e)[:100]}...\")\n",
    "\n",
    "print(f\"\\n  Validation ensures data fits within hardware constraints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d367194",
   "metadata": {},
   "source": [
    "## 9. Audit Logger\n",
    "\n",
    "**Description**: Records all operations on quantum data and algorithms. Tracks who did what, when, and what resources were used for compliance.\n",
    "\n",
    "**Use Case**: Audit iris data processing operations for compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.audit import AuditLogger\n",
    "\n",
    "# Create audit logger\n",
    "auditor = AuditLogger(max_events=1000)\n",
    "\n",
    "print(\"Audit Logger Example:\")\n",
    "\n",
    "# Log various events\n",
    "auditor.log_event(\n",
    "    event_type='data_access',\n",
    "    user='data_scientist',\n",
    "    action='loaded iris dataset',\n",
    "    resource='iris.csv',\n",
    "    status='success',\n",
    "    details={'rows': 150, 'features': 4}\n",
    ")\n",
    "\n",
    "auditor.log_event(\n",
    "    event_type='algorithm_run',\n",
    "    user='data_scientist',\n",
    "    action='executed quantum classifier',\n",
    "    resource='QuantumSVC',\n",
    "    status='success',\n",
    "    details={'accuracy': 0.95, 'samples': 120}\n",
    ")\n",
    "\n",
    "auditor.log_event(\n",
    "    event_type='config_change',\n",
    "    user='admin',\n",
    "    action='updated privacy epsilon',\n",
    "    resource='privacy_config',\n",
    "    status='success',\n",
    "    details={'old_epsilon': 1.0, 'new_epsilon': 0.5}\n",
    ")\n",
    "\n",
    "# Display audit log\n",
    "print(f\"\\n  Total events logged: {len(auditor.events)}\")\n",
    "print(f\"\\n  Recent events:\")\n",
    "for i, event in enumerate(auditor.events[-3:], 1):\n",
    "    print(f\"\\n    Event {i}:\")\n",
    "    print(f\"      Type: {event.event_type}\")\n",
    "    print(f\"      User: {event.user}\")\n",
    "    print(f\"      Action: {event.action}\")\n",
    "    print(f\"      Status: {event.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17283a3f",
   "metadata": {},
   "source": [
    "## 10. Secure Access Control\n",
    "\n",
    "**Description**: Manages user authentication and role-based access control (RBAC). Enforces fine-grained permissions on resources and operations.\n",
    "\n",
    "**Use Case**: Control access to iris data and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee46113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.security import SecureAccessControl, AccessLevel\n",
    "\n",
    "# Create access control\n",
    "access_control = SecureAccessControl()\n",
    "\n",
    "print(\"Secure Access Control Example:\")\n",
    "\n",
    "# Add users with different roles\n",
    "access_control.add_user('alice', 'password123', AccessLevel.ADMIN)\n",
    "access_control.add_user('bob', 'password456', AccessLevel.USER)\n",
    "access_control.add_user('charlie', 'password789', AccessLevel.VIEWER)\n",
    "\n",
    "print(f\"\\n  Users created:\")\n",
    "print(f\"    alice: ADMIN\")\n",
    "print(f\"    bob: USER\")\n",
    "print(f\"    charlie: VIEWER\")\n",
    "\n",
    "# Authenticate users\n",
    "auth_alice, token_alice = access_control.authenticate('alice', 'password123')\n",
    "auth_bob, token_bob = access_control.authenticate('bob', 'password456')\n",
    "auth_fail, _ = access_control.authenticate('bob', 'wrongpassword')\n",
    "\n",
    "print(f\"\\n  Authentication results:\")\n",
    "print(f\"    Alice login: {'SUCCESS' if auth_alice else 'FAILED'}\")\n",
    "print(f\"    Bob login: {'SUCCESS' if auth_bob else 'FAILED'}\")\n",
    "print(f\"    Bob with wrong password: {'FAILED' if not auth_fail else 'SUCCESS'}\")\n",
    "\n",
    "# Check permissions\n",
    "print(f\"\\n  Permissions:\")\n",
    "alice_perms = access_control.check_permission('alice', 'users:manage')\n",
    "bob_perms = access_control.check_permission('bob', 'users:manage')\n",
    "print(f\"    Alice can manage users: {alice_perms}\")\n",
    "print(f\"    Bob can manage users: {bob_perms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66eb93f4",
   "metadata": {},
   "source": [
    "## 11. Workflow Orchestration\n",
    "\n",
    "**Description**: Orchestrates execution of interdependent quantum tasks. Manages scheduling, dependency resolution, error handling, and parallel execution.\n",
    "\n",
    "**Use Case**: Create iris data processing workflow with multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08862a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qudet.governance.orchestration import Workflow, Task, TaskStatus, WorkflowStatus\n",
    "\n",
    "# Create workflow\n",
    "workflow = Workflow(\n",
    "    workflow_name='Iris ML Pipeline',\n",
    "    description='Complete ML pipeline for iris dataset'\n",
    ")\n",
    "\n",
    "print(\"Workflow Orchestration Example:\")\n",
    "\n",
    "# Add tasks\n",
    "task1_id = workflow.add_task(\n",
    "    name='Load Data',\n",
    "    operation='data_loading',\n",
    "    params={'dataset': 'iris.csv', 'split_ratio': 0.8}\n",
    ")\n",
    "\n",
    "task2_id = workflow.add_task(\n",
    "    name='Feature Scaling',\n",
    "    operation='preprocessing',\n",
    "    params={'method': 'standard_scaler'},\n",
    "    dependencies=[task1_id]\n",
    ")\n",
    "\n",
    "task3_id = workflow.add_task(\n",
    "    name='Train Quantum Classifier',\n",
    "    operation='model_training',\n",
    "    params={'algorithm': 'QuantumSVC', 'n_qubits': 4},\n",
    "    dependencies=[task2_id]\n",
    ")\n",
    "\n",
    "task4_id = workflow.add_task(\n",
    "    name='Evaluate Model',\n",
    "    operation='evaluation',\n",
    "    params={'metrics': ['accuracy', 'f1']},\n",
    "    dependencies=[task3_id]\n",
    ")\n",
    "\n",
    "print(f\"\\n  Workflow: {workflow.workflow_name}\")\n",
    "print(f\"  Description: {workflow.description}\")\n",
    "print(f\"\\n  Tasks:\")\n",
    "print(f\"    1. Load Data\")\n",
    "print(f\"    2. Feature Scaling (depends on 1)\")\n",
    "print(f\"    3. Train Classifier (depends on 2)\")\n",
    "print(f\"    4. Evaluate (depends on 3)\")\n",
    "\n",
    "# Get workflow graph\n",
    "graph_info = workflow.get_execution_graph()\n",
    "print(f\"\\n  Execution graph: {len(graph_info)} task dependencies mapped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a529f2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the comprehensive governance capabilities of QDET:\n",
    "\n",
    "### Cost & Resource Management\n",
    "- **Resource Estimator**: Budget quantum jobs and check feasibility\n",
    "\n",
    "### Data Quality & Monitoring\n",
    "- **Quantum Drift Detector**: Monitor for data distribution changes\n",
    "- **Data Integrity Check**: Verify quantum encoding preservation\n",
    "- **Job Monitor**: Track pipeline execution progress\n",
    "\n",
    "### Privacy & Security\n",
    "- **Quantum Differential Privacy**: Protect data when using cloud QPUs\n",
    "- **Noise Simulator**: Test robustness against hardware errors\n",
    "- **Secure Access Control**: Manage authentication and permissions\n",
    "\n",
    "### Validation & Compliance\n",
    "- **Validation**: Ensure data fits hardware constraints\n",
    "- **Audit Logger**: Record all operations for compliance\n",
    "\n",
    "### Orchestration\n",
    "- **Workflow Orchestration**: Coordinate complex multi-task pipelines\n",
    "\n",
    "### Key Insights\n",
    "1. **Enterprise-Ready**: Features for production quantum ML systems\n",
    "2. **Compliance**: Comprehensive audit trails and access control\n",
    "3. **Robustness**: Privacy, noise simulation, and drift detection\n",
    "4. **Scalability**: Cost estimation and resource management\n",
    "5. **Integration**: Works with QDET analytics, transforms, and encoders\n",
    "\n",
    "### Next Steps\n",
    "- Combine governance tools with analytics algorithms\n",
    "- Deploy audit logging in production pipelines\n",
    "- Use orchestration for complex multi-step workflows\n",
    "- Monitor data drift and retrain models proactively"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
